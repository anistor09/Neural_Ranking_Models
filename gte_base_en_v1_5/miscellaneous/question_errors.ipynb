{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "\n",
    "if not pt.started():\n",
    "\n",
    "    pt.init(tqdm=\"notebook\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset(\"irds:beir/cqadupstack/english\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "beir/cqadupstack/english documents:   0%|          | 0/40221 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2cf2456d344340eab804348ff2b8b525"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "max_doc_id_length = 6\n",
    "indexer = pt.IterDictIndexer(\n",
    "    str(Path.cwd()),  # this will be ignored\n",
    "    type=pt.index.IndexingType.MEMORY,  meta={'docno': max_doc_id_length}\n",
    ")\n",
    "index_ref = indexer.index(dataset.get_corpus_iter(), fields=[\"text\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do you have any idea why in the following 2 cells you would have to get the 'text' topics in order to make it work? I have also attached the link to the ir datasets but it is not mentioned why they pass this parameter(https://ir-datasets.com/beir.html#beir/nfcorpus:~:text=%22beir/cqadupstack/english%22). I just wanted to check if my understanding is good. This topics are like queries and we have more type of queries. Given that not all the datasets have queries/topics divided in subcategories, for this dataset we need to select a subclass of topics as there are more"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:37:06.460 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": "       name     RR@10   nDCG@10    AP@100\n0  BR(BM25)  0.284848  0.279502  0.252386",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BR(BM25)</td>\n      <td>0.284848</td>\n      <td>0.279502</td>\n      <td>0.252386</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "\n",
    "bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\")\n",
    "testset = pt.get_dataset(\"irds:beir/cqadupstack/english\")\n",
    "pt.Experiment(\n",
    "    [bm25],\n",
    "    testset.get_topics('text'),\n",
    "    testset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 100],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are multiple query fields available: ('text', 'tags'). To use with pyterrier, provide variant or modify dataframe to add query column.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pandas' object has no attribute 'query'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m bm25 \u001B[38;5;241m=\u001B[39m pt\u001B[38;5;241m.\u001B[39mBatchRetrieve(index_ref, wmodel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBM25\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m testset \u001B[38;5;241m=\u001B[39m pt\u001B[38;5;241m.\u001B[39mget_dataset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mirds:beir/cqadupstack/english\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mpt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mExperiment\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mbm25\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtestset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_topics\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtestset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_qrels\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_metrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mRR\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnDCG\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMAP\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/pipelines.py:471\u001B[0m, in \u001B[0;36mExperiment\u001B[0;34m(retr_systems, topics, qrels, eval_metrics, names, perquery, dataframe, batch_size, filter_by_qrels, filter_by_topics, baseline, test, correction, correction_alpha, highlight, round, verbose, save_dir, save_mode, **kwargs)\u001B[0m\n\u001B[1;32m    468\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m save_dir \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    469\u001B[0m     save_file \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(save_dir, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.res.gz\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m name)\n\u001B[0;32m--> 471\u001B[0m time, evalMeasuresDict \u001B[38;5;241m=\u001B[39m \u001B[43m_run_and_evaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    472\u001B[0m \u001B[43m    \u001B[49m\u001B[43msystem\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_metrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    473\u001B[0m \u001B[43m    \u001B[49m\u001B[43mperquery\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mperquery\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    474\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    475\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbackfill_qids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_topic_qids\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mperquery\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    476\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    477\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    478\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpbar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpbar\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m baseline \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    481\u001B[0m     evalDictsPerQ\u001B[38;5;241m.\u001B[39mappend(evalMeasuresDict)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/pipelines.py:192\u001B[0m, in \u001B[0;36m_run_and_evaluate\u001B[0;34m(system, topics, qrels, metrics, pbar, save_mode, save_file, perquery, batch_size, backfill_qids)\u001B[0m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;66;03m#transformer, evaluate all queries at once\u001B[39;00m\n\u001B[1;32m    191\u001B[0m     starttime \u001B[38;5;241m=\u001B[39m timer()\n\u001B[0;32m--> 192\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43msystem\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    193\u001B[0m     endtime \u001B[38;5;241m=\u001B[39m timer()\n\u001B[1;32m    194\u001B[0m     runtime \u001B[38;5;241m=\u001B[39m  (endtime \u001B[38;5;241m-\u001B[39m starttime) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000.\u001B[39m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/batchretrieve.py:441\u001B[0m, in \u001B[0;36mBatchRetrieve.transform\u001B[0;34m(self, queries)\u001B[0m\n\u001B[1;32m    439\u001B[0m         \u001B[38;5;28miter\u001B[39m \u001B[38;5;241m=\u001B[39m tqdm(\u001B[38;5;28miter\u001B[39m, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m), total\u001B[38;5;241m=\u001B[39mqueries\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m:\n\u001B[0;32m--> 441\u001B[0m         res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retrieve_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_results\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocno_provided\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdocno_provided\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocid_provided\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdocid_provided\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscores_provided\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscores_provided\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    442\u001B[0m         results\u001B[38;5;241m.\u001B[39mextend(res)\n\u001B[1;32m    444\u001B[0m res_dt \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(results, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mqid\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdocid\u001B[39m\u001B[38;5;124m'\u001B[39m ] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetadata \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrank\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/batchretrieve.py:305\u001B[0m, in \u001B[0;36mBatchRetrieve._retrieve_one\u001B[0;34m(self, row, input_results, docno_provided, docid_provided, scores_provided)\u001B[0m\n\u001B[1;32m    303\u001B[0m rank \u001B[38;5;241m=\u001B[39m FIRST_RANK\n\u001B[1;32m    304\u001B[0m qid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(row\u001B[38;5;241m.\u001B[39mqid)\n\u001B[0;32m--> 305\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[43mrow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery\u001B[49m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(query) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    307\u001B[0m     warn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSkipping empty query for qid \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m qid)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Pandas' object has no attribute 'query'"
     ]
    }
   ],
   "source": [
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "\n",
    "bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\")\n",
    "testset = pt.get_dataset(\"irds:beir/cqadupstack/english\")\n",
    "pt.Experiment(\n",
    "    [bm25],\n",
    "    testset.get_topics(),\n",
    "    testset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 100],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
