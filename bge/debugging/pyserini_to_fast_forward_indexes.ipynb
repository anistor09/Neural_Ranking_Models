{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Na3NTzgvKlR"
   },
   "source": [
    "# Converting a Pyserini FAISS index to a Fast-Forward index\n",
    "\n",
    "We'll use [this](https://github.com/castorini/pyserini/blob/9db25847829a656d1c9eacb267bf745f7522dd14/pyserini/prebuilt_index_info.py#L3482) index.\n",
    "\n",
    "First, download and extract the files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    },
    "id": "DSsk5fB7vKlR"
   },
   "outputs": [],
   "source": [
    "!wget https://rgw.cs.uwaterloo.ca/pyserini/indexes/faiss/faiss-flat.beir-v1.0.0-fiqa.contriever.20230124.tar.gz\n",
    "!tar xf faiss-flat.beir-v1.0.0-fiqa.contriever.20230124.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RC3PhA9cvKlR"
   },
   "source": [
    "Since Pyserini indexes are for dense retrieval, you'll need the [FAISS library](https://github.com/facebookresearch/faiss) to load them.\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install faiss-cpu"
   ],
   "metadata": {
    "id": "DP2KTFjtvb-_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then reconstruct all vectors:"
   ],
   "metadata": {
    "id": "am2mKDEcvhUQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8er2NvS-vKlR"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.read_index(\"faiss-flat.beir-v1.0.0-fiqa.contriever.20230124/index\")\n",
    "with open(\"faiss-flat.beir-v1.0.0-fiqa.contriever.20230124/docid\") as fp:\n",
    "    docids = list(fp.read().splitlines())\n",
    "vectors = index.reconstruct_n(0, len(docids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eQHsv1UvKlR"
   },
   "source": [
    "Now we have two arrays; one contains all document representations and the other contains the corresponding IDs. We can use those to create a Fast-Forward index:\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install fast-forward-indexes==0.2.0"
   ],
   "metadata": {
    "id": "bkEfhk1cvxC4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUUiOG7ZvKlS"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from fast_forward import OnDiskIndex\n",
    "\n",
    "OnDiskIndex(Path(\"beir-v1.0.0-fiqa.contriever_ff.h5\"), 768).add(vectors, doc_ids=docids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmRVYPxKvKlT"
   },
   "source": [
    "# Using the index\n",
    "\n",
    "The index we created is for the [Contriever](https://github.com/facebookresearch/contriever) encoder. The model is available [here](https://huggingface.co/facebook/contriever).\n",
    "\n",
    "Since the model is based on a Transformer encoder, we can subclass `fast_forward.encoder.TransformerEncoder` to implement a Fast-Forward query encoder. The code is simply copied from the readme found at the link above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdPgYjlZvKlT"
   },
   "outputs": [],
   "source": [
    "from fast_forward.encoder import TransformerEncoder\n",
    "import torch\n",
    "\n",
    "\n",
    "class ContrieverEncoder(TransformerEncoder):\n",
    "    def __call__(self, texts):\n",
    "        inputs = self.tokenizer(\n",
    "            texts, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        def mean_pooling(token_embeddings, mask):\n",
    "            token_embeddings = token_embeddings.masked_fill(\n",
    "                ~mask[..., None].bool(), 0.0\n",
    "            )\n",
    "            sentence_embeddings = (\n",
    "                token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "            )\n",
    "            return sentence_embeddings\n",
    "\n",
    "        return mean_pooling(outputs[0], inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-kIw3mlvKlT"
   },
   "source": [
    "Now we can load the index we just created and attach a query encoder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0BnLB-kvKlT"
   },
   "outputs": [],
   "source": [
    "from fast_forward import OnDiskIndex, Mode\n",
    "from pathlib import Path\n",
    "\n",
    "ff_index = OnDiskIndex.load(\n",
    "    Path(\"beir-v1.0.0-fiqa.contriever_ff.h5\"),\n",
    "    ContrieverEncoder(\"facebook/contriever\"),\n",
    "    Mode.MAXP,\n",
    ").to_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ocmdQpjvKlU"
   },
   "source": [
    "This index can be used, for example, in a PyTerrier pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!wget https://rgw.cs.uwaterloo.ca/pyserini/indexes/faiss/faiss-flat.beir-v1.0.0-fiqa.contriever.20230124.tar.gz -P /home/anistor/anistor-Neural-ranking-models/bge/dense_indexes/\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!tar xf /home/anistor/anistor-Neural-ranking-models/bge/dense_indexes/faiss-flat.beir-v1.0.0-fiqa.contriever.20230124.tar.gz -C  /home/anistor/anistor-Neural-ranking-models/bge/dense_indexes/\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!rm /home/anistor/anistor-Neural-ranking-models/bge/dense_indexes/faiss-flat.beir-v1.0.0-fiqa.contriever.20230124.tar.gz\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
