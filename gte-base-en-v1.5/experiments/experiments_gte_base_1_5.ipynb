{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "General Setup for all the datasets( first 3 cells)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "from experiment_utils.experiments_helper import time_fct\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluation metrics used for all the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "\n",
    "eval_metrics = [RR @ 10, nDCG @ 10, MAP @ 100]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the query encoder that will run on CPU. Encoder used for embedding all the datasets/queries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from encoders.gte_base_en_encoder import GTEBaseDocumentEncoder\n",
    "\n",
    "q_encoder = GTEBaseDocumentEncoder(\"Alibaba-NLP/gte-base-en-v1.5\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defined the path to root"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In case you would like to directly run the pipeline you can skip until this cell: \"Same experiment as above using the default_complete_test_pipeline_name methods\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "path_to_root = \"../../\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NFCorpus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from experiment_utils.experiments_helper import load_sparse_index_from_disk\n",
    "\n",
    "dataset_name = \"irds:beir/nfcorpus\"\n",
    "model_name = \"gte-base-en-v1.5\"\n",
    "\n",
    "retriever = load_sparse_index_from_disk(dataset_name, path_to_root)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing the sparse retrieval"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment took 6.507 seconds to execute.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                       name     RR@10   nDCG@10    AP@100\n0  irds:beir/nfcorpus: BM25  0.534378  0.322219  0.143582",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>irds:beir/nfcorpus: BM25</td>\n      <td>0.534378</td>\n      <td>0.322219</td>\n      <td>0.143582</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment_utils.experiments_helper import run_single_experiment_name\n",
    "\n",
    "dataset_test_name = \"irds:beir/nfcorpus/test\"\n",
    "run_single_experiment_name(retriever, dataset_test_name, eval_metrics, dataset_name + \": BM25\", timed=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Retrieve the dense index(already loaded into memory)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3633/3633 [00:00<00:00, 1133098.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from experiment_utils.experiments_helper import load_dense_index_from_disk\n",
    "\n",
    "dense_index = load_dense_index_from_disk(dataset_name, q_encoder, model_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from fast_forward.util.pyterrier import FFScore\n",
    "\n",
    "from fast_forward.util.pyterrier import FFInterpolate\n",
    "\n",
    "ff_score = FFScore(dense_index)\n",
    "ff_int = FFInterpolate(alpha=0.05)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find most optimal alpha from default set [0.25, 0.05, 0.1, 0.5, 0.9]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GridScan: 100%|██████████| 4/4 [00:43<00:00, 10.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best map is 0.126401\n",
      "Best setting is ['<fast_forward.util.pyterrier.FFInterpolate object at 0x7f33dc35eb90> alpha=0.01']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from experiment_utils.experiments_helper import find_optimal_alpha_name\n",
    "\n",
    "dev_set_name = \"irds:beir/nfcorpus/dev\"\n",
    "pipeline_find_alpha = retriever % 100 >> ff_score >> ff_int\n",
    "find_optimal_alpha_name(pipeline_find_alpha, ff_int, dev_set_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create pipeline with 1000 docs retrieved per query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment took 11.892 seconds to execute.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           name     RR@10   nDCG@10    AP@100\n0  irds:beir/nfcorpus: BM25 >> gte-base-en-v1.5  0.582751  0.364177  0.166036",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>irds:beir/nfcorpus: BM25 &gt;&gt; gte-base-en-v1.5</td>\n      <td>0.582751</td>\n      <td>0.364177</td>\n      <td>0.166036</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment_utils.experiments_helper import run_single_experiment_name\n",
    "\n",
    "dataset_test_name = \"irds:beir/nfcorpus/test\"\n",
    "\n",
    "pipeline = retriever % 1000 >> ff_score >> ff_int\n",
    "\n",
    "run_single_experiment_name(pipeline, dataset_test_name, eval_metrics, dataset_name + \": BM25 >> gte-base-en-v1.5\",\n",
    "                           timed=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Same experiment as above using the default_complete_test_pipeline_name methods. In the following experiments, the alpha tuning is not used and we preset it to 0.05. We only wanted to see how fast each experiment. Timeit library was not used because I wanted to first understand if these are normal running times overall and then assess the latency for each experiment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3633/3633 [00:00<00:00, 843597.77it/s]\n",
      "GridScan: 100%|██████████| 4/4 [00:41<00:00, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best map is 0.126401\n",
      "Best setting is ['<fast_forward.util.pyterrier.FFInterpolate object at 0x7f33d7a33ee0> alpha=0.01']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run_single_experiment() got an unexpected keyword argument 'alpha'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m dataset_test_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mirds:beir/nfcorpus/test\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      6\u001B[0m pipeline_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBM25 >> \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m model_name\n\u001B[0;32m----> 8\u001B[0m \u001B[43mdefault_test_pipeline_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset_test_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_encoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_metrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpipeline_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mpath_to_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdev_set_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdev_set_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/experiment_utils/experiments_helper.py:120\u001B[0m, in \u001B[0;36mdefault_test_pipeline_name\u001B[0;34m(dataset_name, test_set_name, q_encoder, eval_metrics, model_name, pipeline_name, path_to_root, dev_set_name, timed, alpha)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_test_pipeline_name\u001B[39m(dataset_name, test_set_name, q_encoder, eval_metrics, model_name, pipeline_name,\n\u001B[1;32m    117\u001B[0m                                path_to_root, dev_set_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, timed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.05\u001B[39m):\n\u001B[1;32m    118\u001B[0m     test_topics, test_qrels, dev_topics, dev_qrels \u001B[38;5;241m=\u001B[39m get_test_dev_sets(test_set_name, dev_set_name)\n\u001B[0;32m--> 120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdefault_test_pipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_topics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_qrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_encoder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    121\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43meval_metrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpipeline_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath_to_root\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mdev_topics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdev_qrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/experiment_utils/experiments_helper.py:155\u001B[0m, in \u001B[0;36mdefault_test_pipeline\u001B[0;34m(dataset_name, test_topics, test_qrels, q_encoder, eval_metrics, model_name, pipeline_name, path_to_root, dev_topics, dev_qrels, timed, alpha)\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_test_pipeline\u001B[39m(dataset_name, test_topics, test_qrels, q_encoder, eval_metrics, model_name, pipeline_name,\n\u001B[1;32m    149\u001B[0m                           path_to_root, dev_topics\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dev_qrels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, timed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.05\u001B[39m):\n\u001B[1;32m    150\u001B[0m     default_pipeline, experiment_name \u001B[38;5;241m=\u001B[39m load_pipeline_dependencies(dataset_name, q_encoder, model_name,\n\u001B[1;32m    151\u001B[0m                                                                    pipeline_name,\n\u001B[1;32m    152\u001B[0m                                                                    path_to_root, dev_topics\u001B[38;5;241m=\u001B[39mdev_topics,\n\u001B[1;32m    153\u001B[0m                                                                    dev_qrels\u001B[38;5;241m=\u001B[39mdev_qrels, alpha\u001B[38;5;241m=\u001B[39malpha)\n\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrun_single_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdefault_pipeline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_topics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_qrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_metrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexperiment_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: run_single_experiment() got an unexpected keyword argument 'alpha'"
     ]
    }
   ],
   "source": [
    "from experiment_utils.experiments_helper import default_test_pipeline_name\n",
    "\n",
    "dataset_name = \"irds:beir/nfcorpus\"\n",
    "dev_set_name = \"irds:beir/nfcorpus/dev\"\n",
    "dataset_test_name = \"irds:beir/nfcorpus/test\"\n",
    "pipeline_name = \"BM25 >> \" + model_name\n",
    "\n",
    "default_test_pipeline_name(dataset_name, dataset_test_name, q_encoder, eval_metrics, model_name, pipeline_name,\n",
    "                           path_to_root, dev_set_name=dev_set_name, timed=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run pipeline for FIQA dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from experiment_utils.experiments_helper import default_test_pipeline_name\n",
    "\n",
    "dataset_name = \"irds:beir/fiqa\"\n",
    "dev_set_name = \"irds:beir/fiqa/dev\"\n",
    "dataset_test_name = \"irds:beir/fiqa/test\"\n",
    "\n",
    "default_test_pipeline_name(dataset_name, dataset_test_name, q_encoder, eval_metrics, model_name, pipeline_name,\n",
    "                           path_to_root, dev_set_name=dev_set_name, timed=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## For the Scidocs dataset, considering the lack of a dev set, the train set was used for finetuning the alpha value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from experiment_utils.experiments_helper import  default_test_pipeline_name\n",
    "\n",
    "dataset_name = \"irds:beir/scidocs\"\n",
    "dataset = pt.get_dataset(dataset_name)\n",
    "test_topics = dataset.get_topics('text')\n",
    "\n",
    "default_test_pipeline_name(dataset_name, dataset.get_qrels(), test_topics, q_encoder,eval_metrics, model_name, pipeline_name,\n",
    "path_to_root, timed=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A similar approach is also followed for the \"cqadupstack/english\" dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40221/40221 [00:00<00:00, 1227563.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment took 153.739 seconds to execute.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                            name     RR@10   nDCG@10    AP@100\n0  cqadupstack/english: BM25 >> gte-base-en-v1.5  0.366865  0.356954  0.326041",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cqadupstack/english: BM25 &gt;&gt; gte-base-en-v1.5</td>\n      <td>0.366865</td>\n      <td>0.356954</td>\n      <td>0.326041</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment_utils.experiments_helper import split_dev_test, default_complete_test_pipeline\n",
    "\n",
    "dataset_name = \"cqadupstack/english\"\n",
    "dataset = pt.get_dataset(\"irds:beir/cqadupstack/english\")\n",
    "topics = dataset.get_topics('text')\n",
    "\n",
    "dev_topics, test_topics = split_dev_test(topics, test_size=0.8)\n",
    "\n",
    "time_fct(default_complete_test_pipeline, dataset_name, dataset.get_qrels(), test_topics, q_encoder, eval_metrics)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A similar approach is also followed for the \"arguana\" dataset.\n",
    "\n",
    "### DelftBlue runtime : 15 minutes. Local runtime : 20 minutes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8674/8674 [00:00<00:00, 851624.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment took 1163.829 seconds to execute.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                name     RR@10   nDCG@10    AP@100\n0  arguana: BM25 >> gte-base-en-v1.5  0.252108  0.376144  0.262613",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>arguana: BM25 &gt;&gt; gte-base-en-v1.5</td>\n      <td>0.252108</td>\n      <td>0.376144</td>\n      <td>0.262613</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment_utils.experiments_helper import split_dev_test, default_complete_test_pipeline\n",
    "\n",
    "dataset_name = \"arguana\"\n",
    "dataset = pt.get_dataset(\"irds:beir/arguana\")\n",
    "topics = dataset.get_topics()\n",
    "\n",
    "dev_topics, test_topics = split_dev_test(topics, test_size=0.8)\n",
    "\n",
    "time_fct(default_complete_test_pipeline, dataset_name, dataset.get_qrels(), test_topics, q_encoder,\n",
    "         eval_metrics)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Will rerun this cell after reindexing the dense index as there is a problem with some documents not being found( no vectors for...). Is it possible that I made the dense index correctly and the \"irds:beir/scifact/test\" misses some documents that are tested in \"irds:beir/scifact\". The error is also reproduced in the debug.ipynb where it can be observed that using only the sparse index does not cause any error so for that reason I think it is because of the dense one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 1446475.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment took 30.021 seconds to execute.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                name     RR@10   nDCG@10    AP@100\n0  scifact: BM25 >> gte-base-en-v1.5  0.669475  0.708775  0.664073",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>scifact: BM25 &gt;&gt; gte-base-en-v1.5</td>\n      <td>0.669475</td>\n      <td>0.708775</td>\n      <td>0.664073</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment_utils.experiments_helper import default_complete_test_pipeline_name\n",
    "\n",
    "dataset_name = \"scifact\"\n",
    "# dev_set_name = \"irds:beir/scifact/train\"\n",
    "dataset_test_name = \"irds:beir/scifact/test\"\n",
    "\n",
    "time_fct(\n",
    "    default_complete_test_pipeline_name, dataset_name, dataset_test_name, q_encoder, eval_metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
