{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "General Setup for all the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluation metrics used for all the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "\n",
    "eval_metrics = [RR @ 10, nDCG @ 10, MAP @ 100]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the query encoder that will run on CPU. Encoder used for embedding all the datasets/queries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from gte_base_en_encoder import GTEBaseDocumentEncoder\n",
    "\n",
    "q_encoder = GTEBaseDocumentEncoder(\"Alibaba-NLP/gte-base-en-v1.5\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NFCorpus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from experiments_helper import load_sparse_index_from_disk\n",
    "\n",
    "dataset_name = \"nfcorpus\"\n",
    "\n",
    "retriever = load_sparse_index_from_disk(dataset_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing the sparse retrieval"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   name     RR@10   nDCG@10    AP@100\n0  BM25  0.534378  0.322219  0.143582",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BM25</td>\n      <td>0.534378</td>\n      <td>0.322219</td>\n      <td>0.143582</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiments_helper import run_single_experiment_name\n",
    "\n",
    "dataset_test_name = \"irds:beir/nfcorpus/test\"\n",
    "run_single_experiment_name(retriever, dataset_test_name, eval_metrics, \"BM25\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Retrieve the dense index(already loaded into memory)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3633/3633 [00:00<00:00, 923901.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from experiments_helper import load_dense_index_from_disk\n",
    "\n",
    "dense_index = load_dense_index_from_disk(dataset_name, q_encoder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from fast_forward.util.pyterrier import FFScore\n",
    "\n",
    "from fast_forward.util.pyterrier import FFInterpolate\n",
    "\n",
    "ff_score = FFScore(dense_index)\n",
    "ff_int = FFInterpolate(alpha=0.05)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find most optimal alpha from default set [0.25, 0.05, 0.1, 0.5, 0.9]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [starting] opening zip file\n",
      "[INFO] [finished] opening zip file [5ms]\n",
      "GridScan: 100%|██████████| 5/5 [00:41<00:00,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best map is 0.124061\n",
      "Best setting is ['<fast_forward.util.pyterrier.FFInterpolate object at 0x7fbb8f896e00> alpha=0.05']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from experiments_helper import find_optimal_alpha_name\n",
    "\n",
    "dev_set_name = \"irds:beir/nfcorpus/dev\"\n",
    "pipeline_find_alpha = retriever % 100 >> ff_score >> ff_int\n",
    "find_optimal_alpha_name(pipeline_find_alpha, ff_int, dev_set_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create pipeline with 1000 docs retrieved per query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                       name     RR@10   nDCG@10   AP@100\n0  BM25 >> gte-base-en-v1.5  0.553675  0.343964  0.15507",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BM25 &gt;&gt; gte-base-en-v1.5</td>\n      <td>0.553675</td>\n      <td>0.343964</td>\n      <td>0.15507</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiments_helper import run_single_experiment_name\n",
    "\n",
    "dataset_test_name = \"irds:beir/nfcorpus/test\"\n",
    "\n",
    "pipeline = retriever % 1000 >> ff_score >> ff_int\n",
    "run_single_experiment_name(pipeline, dataset_test_name, eval_metrics, \"BM25 >> gte-base-en-v1.5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Same experiment as above using the default_complete_test_pipeline_name methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from experiments_helper import default_complete_test_pipeline_name\n",
    "\n",
    "dataset_name = \"nfcorpus\"\n",
    "dev_set_name = \"irds:beir/nfcorpus/dev\"\n",
    "dataset_test_name = \"irds:beir/nfcorpus/test\"\n",
    "\n",
    "default_complete_test_pipeline_name(dataset_name, dev_set_name, dataset_test_name, q_encoder, eval_metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run pipeline for FIQA dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57638/57638 [00:00<00:00, 1695905.25it/s]\n",
      "GridScan: 100%|██████████| 5/5 [01:51<00:00, 22.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best map is 0.290816\n",
      "Best setting is ['<fast_forward.util.pyterrier.FFInterpolate object at 0x7f086c477250> alpha=0.05']\n"
     ]
    },
    {
     "data": {
      "text/plain": "                             name     RR@10   nDCG@10    AP@100\n0  fiqa: BM25 >> gte-base-en-v1.5  0.399449  0.335966  0.274557",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fiqa: BM25 &gt;&gt; gte-base-en-v1.5</td>\n      <td>0.399449</td>\n      <td>0.335966</td>\n      <td>0.274557</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiments_helper import default_complete_test_pipeline_name\n",
    "\n",
    "dataset_name = \"fiqa\"\n",
    "dev_set_name = \"irds:beir/fiqa/dev\"\n",
    "dataset_test_name = \"irds:beir/fiqa/test\"\n",
    "\n",
    "default_complete_test_pipeline_name(dataset_name, dev_set_name, dataset_test_name, q_encoder, eval_metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## For the Scifact dataset, considering the lack of a dev set, the train set was used for finetuning the alpha value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5136/5136 [00:00<00:00, 977136.23it/s]\n",
      "[INFO] [starting] opening zip file\n",
      "[INFO] [finished] opening zip file [52ms]\n",
      "GridScan:   0%|          | 0/5 [00:00<?, ?it/s]no vectors for 195680777\n",
      "no vectors for 195689316\n",
      "no vectors for 195689757\n",
      "no vectors for 195683603\n",
      "no vectors for 145383432\n",
      "no vectors for 155200372\n",
      "no vectors for 154243324\n",
      "no vectors for 154050141\n",
      "no vectors for 143868995\n",
      "no vectors for 117907685\n",
      "no vectors for 140907540\n",
      "no vectors for 145335387\n",
      "no vectors for 116075383\n",
      "no vectors for 196664003\n",
      "no vectors for 116556376\n",
      "no vectors for 108886332\n",
      "no vectors for 145416918\n",
      "no vectors for 140098548\n",
      "no vectors for 109946221\n",
      "no vectors for 109795294\n",
      "no vectors for 195317463\n",
      "no vectors for 121581019\n",
      "no vectors for 146653163\n",
      "no vectors for 168265642\n",
      "no vectors for 104143831\n",
      "no vectors for 143381103\n",
      "no vectors for 198309074\n",
      "no vectors for 167469018\n",
      "no vectors for 167944455\n",
      "no vectors for 198133135\n",
      "no vectors for 153755807\n",
      "no vectors for 120385993\n",
      "no vectors for 154549459\n",
      "no vectors for 144801076\n",
      "no vectors for 121001457\n",
      "no vectors for 129199129\n",
      "no vectors for 145716849\n",
      "no vectors for 126549848\n",
      "no vectors for 99829811\n",
      "no vectors for 154796494\n",
      "no vectors for 144555102\n",
      "no vectors for 143796742\n",
      "no vectors for 142559798\n",
      "no vectors for 147107523\n",
      "no vectors for 154763124\n",
      "no vectors for 118215171\n",
      "GridScan:  20%|██        | 1/5 [00:51<03:26, 51.58s/it]no vectors for 195680777\n",
      "no vectors for 195689316\n",
      "no vectors for 195689757\n",
      "no vectors for 195683603\n",
      "no vectors for 145383432\n",
      "no vectors for 155200372\n",
      "no vectors for 154243324\n",
      "no vectors for 154050141\n",
      "no vectors for 143868995\n",
      "no vectors for 117907685\n",
      "no vectors for 140907540\n",
      "no vectors for 145335387\n",
      "no vectors for 116075383\n",
      "no vectors for 196664003\n",
      "no vectors for 116556376\n",
      "no vectors for 108886332\n",
      "no vectors for 145416918\n",
      "no vectors for 140098548\n",
      "no vectors for 109946221\n",
      "no vectors for 109795294\n",
      "no vectors for 195317463\n",
      "no vectors for 121581019\n",
      "no vectors for 146653163\n",
      "no vectors for 168265642\n",
      "no vectors for 104143831\n",
      "no vectors for 143381103\n",
      "no vectors for 198309074\n",
      "no vectors for 167469018\n",
      "no vectors for 167944455\n",
      "no vectors for 198133135\n",
      "no vectors for 153755807\n",
      "no vectors for 120385993\n",
      "no vectors for 154549459\n",
      "no vectors for 144801076\n",
      "no vectors for 121001457\n",
      "no vectors for 129199129\n",
      "no vectors for 145716849\n",
      "no vectors for 126549848\n",
      "no vectors for 99829811\n",
      "no vectors for 154796494\n",
      "no vectors for 144555102\n",
      "no vectors for 143796742\n",
      "no vectors for 142559798\n",
      "no vectors for 147107523\n",
      "no vectors for 154763124\n",
      "no vectors for 118215171\n",
      "GridScan:  40%|████      | 2/5 [02:01<03:02, 60.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 8\u001B[0m\n\u001B[1;32m      4\u001B[0m dev_set_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mirds:beir/scifact/train\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      5\u001B[0m dataset_test_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mirds:beir/scifact/test\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 8\u001B[0m \u001B[43mdefault_complete_test_pipeline_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdev_set_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset_test_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_encoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_metrics\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/gte-base-en-v1.5/experiments/experiments_helper.py:107\u001B[0m, in \u001B[0;36mdefault_complete_test_pipeline_name\u001B[0;34m(dataset_name, dev_set_name, test_set_name, q_encoder, eval_metrics)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;66;03m# Pipeline for finding optimal alpha\u001B[39;00m\n\u001B[1;32m    106\u001B[0m pipeline_find_alpha \u001B[38;5;241m=\u001B[39m retriever \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m>>\u001B[39m ff_score \u001B[38;5;241m>>\u001B[39m ff_int\n\u001B[0;32m--> 107\u001B[0m \u001B[43mfind_optimal_alpha_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpipeline_find_alpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mff_int\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdev_set_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    109\u001B[0m experiment_name \u001B[38;5;241m=\u001B[39m dataset_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m: BM25 >> gte-base-en-v1.5\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    110\u001B[0m default_pipeline \u001B[38;5;241m=\u001B[39m retriever \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m1000\u001B[39m \u001B[38;5;241m>>\u001B[39m ff_score \u001B[38;5;241m>>\u001B[39m ff_int\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/gte-base-en-v1.5/experiments/experiments_helper.py:48\u001B[0m, in \u001B[0;36mfind_optimal_alpha_name\u001B[0;34m(pipeline, ff_int, dev_set_name, alpha_vals)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_optimal_alpha_name\u001B[39m(pipeline, ff_int, dev_set_name, alpha_vals\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.25\u001B[39m, \u001B[38;5;241m0.05\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.9\u001B[39m]):\n\u001B[1;32m     47\u001B[0m     dev_set \u001B[38;5;241m=\u001B[39m pt\u001B[38;5;241m.\u001B[39mget_dataset(dev_set_name)\n\u001B[0;32m---> 48\u001B[0m     \u001B[43mfind_optimal_alpha\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpipeline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mff_int\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdev_set\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_topics\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mdev_set\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_qrels\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha_vals\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/gte-base-en-v1.5/experiments/experiments_helper.py:53\u001B[0m, in \u001B[0;36mfind_optimal_alpha\u001B[0;34m(pipeline, ff_int, topics, qrels, alpha_vals)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_optimal_alpha\u001B[39m(pipeline, ff_int, topics, qrels, alpha_vals\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.25\u001B[39m, \u001B[38;5;241m0.05\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.9\u001B[39m]):\n\u001B[0;32m---> 53\u001B[0m     \u001B[43mpt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mGridSearch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpipeline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[43mff_int\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43malpha\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha_vals\u001B[49m\u001B[43m}\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtopics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[43m        \u001B[49m\u001B[43mqrels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmap\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/pipelines.py:752\u001B[0m, in \u001B[0;36mGridSearch\u001B[0;34m(pipeline, params, topics, qrels, metric, jobs, backend, verbose, batch_size, return_type)\u001B[0m\n\u001B[1;32m    749\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(metric, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    750\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGridSearch can only maximise ONE metric, but you passed a list (\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mstr\u001B[39m(metric))\n\u001B[0;32m--> 752\u001B[0m grid_outcomes \u001B[38;5;241m=\u001B[39m \u001B[43mGridScan\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    753\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpipeline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    754\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    755\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtopics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    756\u001B[0m \u001B[43m    \u001B[49m\u001B[43mqrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    757\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    758\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    759\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    760\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    761\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    762\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    764\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(grid_outcomes) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGridScan returned 0 rows\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    765\u001B[0m max_measure \u001B[38;5;241m=\u001B[39m grid_outcomes[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m1\u001B[39m][metric]\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/pipelines.py:892\u001B[0m, in \u001B[0;36mGridScan\u001B[0;34m(pipeline, params, topics, qrels, metrics, jobs, backend, verbose, batch_size, dataframe)\u001B[0m\n\u001B[1;32m    890\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    891\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m tqdm(combinations, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(combinations), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGridScan\u001B[39m\u001B[38;5;124m\"\u001B[39m, mininterval\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m verbose \u001B[38;5;28;01melse\u001B[39;00m combinations:\n\u001B[0;32m--> 892\u001B[0m         parameter_list, eval_scores \u001B[38;5;241m=\u001B[39m \u001B[43m_evaluate_one_setting\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    893\u001B[0m         eval_list\u001B[38;5;241m.\u001B[39mappend( (parameter_list, eval_scores) )\n\u001B[1;32m    894\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/pipelines.py:882\u001B[0m, in \u001B[0;36mGridScan.<locals>._evaluate_one_setting\u001B[0;34m(keys, values)\u001B[0m\n\u001B[1;32m    879\u001B[0m     \u001B[38;5;66;03m# such as (BatchRetrieve, 'wmodel', 'BM25')\u001B[39;00m\n\u001B[1;32m    880\u001B[0m     parameter_list\u001B[38;5;241m.\u001B[39mappend( (tran, param_name, value) )\n\u001B[0;32m--> 882\u001B[0m time, eval_scores \u001B[38;5;241m=\u001B[39m \u001B[43m_run_and_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpipeline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mperquery\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m parameter_list, eval_scores\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/pipelines.py:192\u001B[0m, in \u001B[0;36m_run_and_evaluate\u001B[0;34m(system, topics, qrels, metrics, pbar, save_mode, save_file, perquery, batch_size, backfill_qids)\u001B[0m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;66;03m#transformer, evaluate all queries at once\u001B[39;00m\n\u001B[1;32m    191\u001B[0m     starttime \u001B[38;5;241m=\u001B[39m timer()\n\u001B[0;32m--> 192\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43msystem\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    193\u001B[0m     endtime \u001B[38;5;241m=\u001B[39m timer()\n\u001B[1;32m    194\u001B[0m     runtime \u001B[38;5;241m=\u001B[39m  (endtime \u001B[38;5;241m-\u001B[39m starttime) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000.\u001B[39m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/ops.py:335\u001B[0m, in \u001B[0;36mComposedPipeline.transform\u001B[0;34m(self, topics)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\u001B[38;5;28mself\u001B[39m, topics):\n\u001B[1;32m    334\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels:\n\u001B[0;32m--> 335\u001B[0m         topics \u001B[38;5;241m=\u001B[39m \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    336\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m topics\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/ops.py:335\u001B[0m, in \u001B[0;36mComposedPipeline.transform\u001B[0;34m(self, topics)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\u001B[38;5;28mself\u001B[39m, topics):\n\u001B[1;32m    334\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels:\n\u001B[0;32m--> 335\u001B[0m         topics \u001B[38;5;241m=\u001B[39m \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    336\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m topics\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/fast_forward/util/pyterrier.py:30\u001B[0m, in \u001B[0;36mFFScore.transform\u001B[0;34m(self, df)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\u001B[38;5;28mself\u001B[39m, df: pd\u001B[38;5;241m.\u001B[39mDataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame:\n\u001B[1;32m     21\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the scores for all query-document pairs in the data frame.\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;124;03m    The previous scores are moved to the \"score_0\" column.\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;124;03m        pd.DataFrame: A new data frame with the computed scores.\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m     ff_scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_index\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m        \u001B[49m\u001B[43mRanking\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrename\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mqid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mq_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdocno\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m            \u001B[49m\u001B[43mis_sorted\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m_df\u001B[38;5;241m.\u001B[39mrename(columns\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mq_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mqid\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocno\u001B[39m\u001B[38;5;124m\"\u001B[39m})\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df[[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mqid\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocno\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\u001B[38;5;241m.\u001B[39mmerge(\n\u001B[1;32m     39\u001B[0m         ff_scores[[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mqid\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocno\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery\u001B[39m\u001B[38;5;124m\"\u001B[39m]],\n\u001B[1;32m     40\u001B[0m         on\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mqid\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocno\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     41\u001B[0m         suffixes\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_0\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m],\n\u001B[1;32m     42\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/fast_forward/index/__init__.py:403\u001B[0m, in \u001B[0;36mIndex.__call__\u001B[0;34m(self, ranking, early_stopping, early_stopping_alpha, early_stopping_intervals)\u001B[0m\n\u001B[1;32m    400\u001B[0m df \u001B[38;5;241m=\u001B[39m ranking\u001B[38;5;241m.\u001B[39m_df\u001B[38;5;241m.\u001B[39mmerge(query_df, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mq_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, suffixes\u001B[38;5;241m=\u001B[39m[\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    402\u001B[0m \u001B[38;5;66;03m# batch encode queries\u001B[39;00m\n\u001B[0;32m--> 403\u001B[0m query_vectors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_queries\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mquery_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mquery\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m early_stopping \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    406\u001B[0m     \u001B[38;5;66;03m# early stopping splits the data frame, hence we need to keep track of the original index\u001B[39;00m\n\u001B[1;32m    407\u001B[0m     df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124morig_index\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mindex\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/fast_forward/index/__init__.py:68\u001B[0m, in \u001B[0;36mIndex.encode_queries\u001B[0;34m(self, queries)\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(queries), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_encoder_batch_size):\n\u001B[1;32m     67\u001B[0m     batch \u001B[38;5;241m=\u001B[39m queries[i : i \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_encoder_batch_size]\n\u001B[0;32m---> 68\u001B[0m     result\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_query_encoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mconcatenate(result)\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/gte-base-en-v1.5/experiments/gte_base_en_encoder.py:37\u001B[0m, in \u001B[0;36mGTEBaseDocumentEncoder.__call__\u001B[0;34m(self, input_texts)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m## NO GRad added by me\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 37\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbatch_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlast_hidden_state[:, \u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# (Optionally) normalize embeddings\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/transformers_modules/Alibaba-NLP/new-impl/b7ea01ba91f26ef946f8c25261151b13aa502268/modeling.py:919\u001B[0m, in \u001B[0;36mNewModel.forward\u001B[0;34m(self, input_ids, attention_mask, length, subset_indices, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, unpad_inputs)\u001B[0m\n\u001B[1;32m    916\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    917\u001B[0m     attention_scale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 919\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    920\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    921\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrope_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrope_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m    \u001B[49m\u001B[43msubset_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubset_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    929\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    930\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    931\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m unpad_inputs \u001B[38;5;129;01mand\u001B[39;00m output_padded:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/transformers_modules/Alibaba-NLP/new-impl/b7ea01ba91f26ef946f8c25261151b13aa502268/modeling.py:736\u001B[0m, in \u001B[0;36mNewEncoder.forward\u001B[0;34m(self, hidden_states, attention_bias, rope_embeds, attention_scale, subset_indices, head_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    726\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    727\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m    728\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    733\u001B[0m         layer_head_mask,\n\u001B[1;32m    734\u001B[0m     )\n\u001B[1;32m    735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 736\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    737\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    738\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    739\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrope_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    740\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    741\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_subset_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    742\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    743\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    744\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    746\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/transformers_modules/Alibaba-NLP/new-impl/b7ea01ba91f26ef946f8c25261151b13aa502268/modeling.py:681\u001B[0m, in \u001B[0;36mNewLayer.forward\u001B[0;34m(self, hidden_states, attention_bias, rope_embeds, attention_scale, subset_indices, head_mask, output_attentions, qkv_inputs, padding_inputs)\u001B[0m\n\u001B[1;32m    679\u001B[0m \u001B[38;5;66;03m# Fully Connected\u001B[39;00m\n\u001B[1;32m    680\u001B[0m residual \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[0;32m--> 681\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_dropout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    683\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_dropout(hidden_states)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/transformers_modules/Alibaba-NLP/new-impl/b7ea01ba91f26ef946f8c25261151b13aa502268/modeling.py:607\u001B[0m, in \u001B[0;36mNewGatedMLP.forward\u001B[0;34m(self, hidden_states)\u001B[0m\n\u001B[1;32m    606\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states):\n\u001B[0;32m--> 607\u001B[0m     up_gate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mup_gate_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m     up_states, gate \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msplit(up_gate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate_size, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    609\u001B[0m     gate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact_fn(gate)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from experiments_helper import default_complete_test_pipeline_name\n",
    "\n",
    "dataset_name = \"scifact\"\n",
    "dev_set_name = \"irds:beir/scifact/train\"\n",
    "dataset_test_name = \"irds:beir/scifact/test\"\n",
    "\n",
    "default_complete_test_pipeline_name(dataset_name, dev_set_name, dataset_test_name, q_encoder, eval_metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given that the scidocs dataset offers only one dataset, we will split it into dev and test set. More exactly, we will split the topics because that is what we are testing against. I chose the 'text' topics as this dataset offers 2 topics categories."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25657/25657 [00:00<00:00, 1241156.78it/s]\n",
      "GridScan: 100%|██████████| 5/5 [00:46<00:00,  9.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best map is 0.024039\n",
      "Best setting is ['<fast_forward.util.pyterrier.FFInterpolate object at 0x7fecf5038f70> alpha=0.05']\n"
     ]
    }
   ],
   "source": [
    "from experiments_helper import split_dev_test, default_complete_test_pipeline\n",
    "\n",
    "dataset_name = \"scidocs\"\n",
    "dataset = pt.get_dataset(\"irds:beir/scidocs\")\n",
    "topics = dataset.get_topics('text')\n",
    "\n",
    "dev_topics, test_topics = split_dev_test(topics, test_size=0.8)\n",
    "\n",
    "default_complete_test_pipeline(dataset_name, dataset.get_qrels(), dev_topics, test_topics, q_encoder, eval_metrics)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A similar approach is also followed for the \"arguana\" dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from experiments_helper import split_dev_test, default_complete_test_pipeline\n",
    "\n",
    "dataset_name = \"arguana\"\n",
    "dataset = pt.get_dataset(\"irds:beir/arguana\")\n",
    "topics = dataset.get_topics()\n",
    "\n",
    "dev_topics, test_topics = split_dev_test(topics, test_size=0.8)\n",
    "\n",
    "default_complete_test_pipeline(dataset_name, dataset.get_qrels(), dev_topics, test_topics, q_encoder, eval_metrics)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A similar approach is also followed for the \"cqadupstack/english\" dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40221/40221 [00:00<00:00, 1703601.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from experiments_helper import split_dev_test, default_complete_test_pipeline, default_complete_test_pipeline_nogrid\n",
    "\n",
    "dataset_name = \"cqadupstack/english\"\n",
    "dataset = pt.get_dataset(\"irds:beir/cqadupstack/english\")\n",
    "topics = dataset.get_topics('text')\n",
    "\n",
    "dev_topics, test_topics = split_dev_test(topics, test_size=0.8)\n",
    "\n",
    "default_complete_test_pipeline_nogrid(dataset_name, dataset.get_qrels(), dev_topics, test_topics, q_encoder, eval_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
