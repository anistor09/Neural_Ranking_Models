{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Trying to run the dense indexing for the MS MARCO dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The sparse index that we will use for our pipeline:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "from experiments_helper import time_fct\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "\n",
    "eval_metrics = [RR @ 10, nDCG @ 10, MAP @ 100]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment took 12.220 seconds to execute.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                    name    RR@10  nDCG@10    AP@100\n0  msmarco_passage: BM25  0.79438  0.47954  0.290692",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>msmarco_passage: BM25</td>\n      <td>0.79438</td>\n      <td>0.47954</td>\n      <td>0.290692</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiments_helper import run_single_experiment_name\n",
    "\n",
    "index_absolute_path = \"/home/anistor/.pyterrier/corpora/msmarco_passage/index/terrier_stemmed\"\n",
    "\n",
    "\n",
    "index = pt.IndexFactory.of(index_absolute_path)\n",
    "\n",
    "bm25_stored = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "dataset_name = \"msmarco_passage\"\n",
    "\n",
    "dataset_test_name = \"irds:msmarco-passage/trec-dl-2019\"\n",
    "time_fct(run_single_experiment_name, bm25_stored, dataset_test_name, eval_metrics, dataset_name + \": BM25\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise the Query and Document encoders for GTE base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from gte_base_en_encoder import GTEBaseDocumentEncoder\n",
    "import torch\n",
    "from fast_forward import OnDiskIndex, Mode, Indexer\n",
    "\n",
    "q_encoder = GTEBaseDocumentEncoder(\"Alibaba-NLP/gte-base-en-v1.5\")\n",
    "d_encoder = GTEBaseDocumentEncoder(\n",
    "    \"Alibaba-NLP/gte-base-en-v1.5\",\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a function that will iterate only the first 1000 docs in order to get an understanding of how much time it would take"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def docs_iter(dataset, limit=1000):\n",
    "    # Iterate over the documents and yield up to 'limit' documents\n",
    "    for count, d in enumerate(dataset.get_corpus_iter()):\n",
    "        if count >= limit:\n",
    "            break\n",
    "        yield {\"doc_id\": d[\"docno\"], \"text\": d[\"text\"]}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Function that formats the dataset name to avoid \":\" in the index filename"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def format_dataset_name(text):\n",
    "    if ':' in text:\n",
    "        return text.split(':')[0] + \"_\" + text.split(':')[1]\n",
    "    else:\n",
    "        return text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The passage that I am willing to index. I assumed that the sparse and dense indexes must embed the exact same dataset, \"msmarco_passage\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dataset_name = \"msmarco_passage\"\n",
    "dataset = pt.get_dataset(dataset_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create indexer and start indexing. I get an error and my understanding is that the files is not available. However, i don't understand the reason for this error as the dataset appears as available on the Pyterrier website(https://pyterrier.readthedocs.io/en/latest/datasets.html#:~:text=Deep%2DLearning.html-,msmarco_passage,-True)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "index_path = \"../dense_indexes/ffindex_\" + dataset_name + \"_gte-base-en-v1.5.h5\"\n",
    "ff_index = OnDiskIndex(\n",
    "    Path(index_path), dim=768, query_encoder=q_encoder, mode=Mode.MAXP, max_id_length=47\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading msmarco_passage tars to /home/anistor/.pyterrier/corpora/msmarco_passage/collection.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: The specified resource does not exist. for url: https://msmarco.blob.core.windows.net/msmarcoranking/collection.tar.gz",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m ff_indexer \u001B[38;5;241m=\u001B[39m Indexer(ff_index, d_encoder, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mff_indexer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex_dicts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocs_iter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/fast_forward/indexer.py:36\u001B[0m, in \u001B[0;36mIndexer.index_dicts\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Index data from dictionaries.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;03mThe dictionaries should have the key \"text\" and at least one of \"doc_id\" and \"psg_id\".\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \n\u001B[1;32m     32\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;124;03m    data (Iterable[Dict[str, str]]): An iterable of the dictionaries.\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     35\u001B[0m texts, doc_ids, psg_ids \u001B[38;5;241m=\u001B[39m [], [], []\n\u001B[0;32m---> 36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m tqdm(data):\n\u001B[1;32m     37\u001B[0m     texts\u001B[38;5;241m.\u001B[39mappend(d[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdoc_id\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m d:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[7], line 3\u001B[0m, in \u001B[0;36mdocs_iter\u001B[0;34m(dataset, limit)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdocs_iter\u001B[39m(dataset, limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m# Iterate over the documents and yield up to 'limit' documents\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m count, d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataset\u001B[38;5;241m.\u001B[39mget_corpus_iter()):\n\u001B[1;32m      4\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m count \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m limit:\n\u001B[1;32m      5\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/datasets.py:555\u001B[0m, in \u001B[0;36mpassage_generate\u001B[0;34m(dataset)\u001B[0m\n\u001B[1;32m    554\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpassage_generate\u001B[39m(dataset):\n\u001B[0;32m--> 555\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m filename \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_corpus\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    556\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m autoopen(filename, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrt\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m corpusfile:\n\u001B[1;32m    557\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m corpusfile: \u001B[38;5;66;03m#for each line\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/datasets.py:335\u001B[0m, in \u001B[0;36mRemoteDataset.get_corpus\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_corpus\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    334\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyterrier\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpt\u001B[39;00m\n\u001B[0;32m--> 335\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m f : \u001B[38;5;129;01mnot\u001B[39;00m f\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.complete\u001B[39m\u001B[38;5;124m\"\u001B[39m), pt\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mfind_files(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_all_files\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcorpus\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)))\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/datasets.py:302\u001B[0m, in \u001B[0;36mRemoteDataset._get_all_files\u001B[0;34m(self, component, variant, **kwargs)\u001B[0m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m intarfile\n\u001B[1;32m    301\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.tar\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m tarname \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.tgz\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m tarname\n\u001B[0;32m--> 302\u001B[0m localtarfile, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_one_file\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtars\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    303\u001B[0m tarobj \u001B[38;5;241m=\u001B[39m tarfile\u001B[38;5;241m.\u001B[39mopen(localtarfile, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    304\u001B[0m tarobj\u001B[38;5;241m.\u001B[39mextract(intarfile, path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcorpus_home)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/datasets.py:226\u001B[0m, in \u001B[0;36mRemoteDataset._get_one_file\u001B[0;34m(self, component, variant)\u001B[0m\n\u001B[1;32m    224\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    225\u001B[0m         kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauth\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpassword)\n\u001B[0;32m--> 226\u001B[0m     \u001B[43mRemoteDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mURL\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m urllib\u001B[38;5;241m.\u001B[39merror\u001B[38;5;241m.\u001B[39mHTTPError \u001B[38;5;28;01mas\u001B[39;00m he:\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not fetch \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m URL) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhe\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/datasets.py:167\u001B[0m, in \u001B[0;36mRemoteDataset.download\u001B[0;34m(URLs, filename, **kwargs)\u001B[0m\n\u001B[1;32m    165\u001B[0m error \u001B[38;5;241m=\u001B[39m e\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m finalattempt:\n\u001B[0;32m--> 167\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    169\u001B[0m     warn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProblem fetching \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m, resorting to next mirror\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m url)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/datasets.py:149\u001B[0m, in \u001B[0;36mRemoteDataset.download\u001B[0;34m(URLs, filename, **kwargs)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    148\u001B[0m     r \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(url, allow_redirects\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 149\u001B[0m     \u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m     total \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(r\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent-length\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m    151\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m pt\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mfinalized_open(filename, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file, tqdm(\n\u001B[1;32m    152\u001B[0m             desc\u001B[38;5;241m=\u001B[39mbasename,\n\u001B[1;32m    153\u001B[0m             total\u001B[38;5;241m=\u001B[39mtotal,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    156\u001B[0m             unit_divisor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1024\u001B[39m,\n\u001B[1;32m    157\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m bar:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py:1021\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1016\u001B[0m     http_error_msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1017\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Server Error: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mreason\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for url: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1018\u001B[0m     )\n\u001B[1;32m   1020\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[0;32m-> 1021\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mHTTPError\u001B[0m: 404 Client Error: The specified resource does not exist. for url: https://msmarco.blob.core.windows.net/msmarcoranking/collection.tar.gz"
     ]
    }
   ],
   "source": [
    "ff_indexer = Indexer(ff_index, d_encoder, batch_size=8)\n",
    "ff_indexer.index_dicts(docs_iter(dataset))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I chose the \"irds\" version of the MC MARCO passage as I have only used irds previously for the BEIR set and I wanted to see if it works. I started indexing and it seemed that it would work. However, I did not know is it is ok to run BM25 on msmarco-passage and the dense index and the test on \"irds:msmarco-passage\". I would like to use the msmarco-passage pre-built index to avoid creating a sparse index for this dataset. Is the previous approach(runnning BM25 on msmarco-passage and the dense index and the testing on \"irds:msmarco-passage\") a good approach or I should avoid it?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "dataset_name = \"irds:msmarco-passage\"\n",
    "dataset = pt.get_dataset(dataset_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "index_path = \"../dense_indexes/ffindex_\" + format_dataset_name(dataset_name) + \"_gte-base-en-v1.5.h5\"\n",
    "ff_index = OnDiskIndex(\n",
    "    Path(index_path), dim=768, query_encoder=q_encoder, mode=Mode.MAXP, max_id_length=47\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "                  cuments:   0%|          | 0/8841823 [00:00<?, ?it/s]\u001B[A\r\n",
      "\u001B[A                                                                   [INFO] Please confirm you agree to the MSMARCO data usage agreement found at <http://www.msmarco.org/dataset.aspx>\n",
      "0it [00:00, ?it/s]\n",
      "                  cuments:   0%|          | 0/8841823 [00:00<?, ?it/s]\u001B[A\r\n",
      "\u001B[A                                                                   [INFO] If you have a local copy of https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz, you can symlink it here to avoid downloading it again: /home/anistor/.ir_datasets/downloads/31644046b18952c1386cd4564ba2ae69\n",
      "0it [00:00, ?it/s]\n",
      "                  cuments:   0%|          | 0/8841823 [00:00<?, ?it/s]\u001B[A\r\n",
      "\u001B[A                                                                   [INFO] [starting] https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz\n",
      "0it [00:00, ?it/s]\n",
      "msmarco-passage documents:   0%|          | 0/8841823 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.0%| 0.00/1.06G [00:00<?, ?B/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.0%| 16.4k/1.06G [00:00<2:52:21, 102kB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.0%| 49.2k/1.06G [00:00<2:09:04, 137kB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.0%| 81.9k/1.06G [00:00<2:01:50, 145kB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.0%| 147k/1.06G [00:00<1:32:28, 191kB/s] \u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.0%| 262k/1.06G [00:00<1:06:14, 266kB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.0%| 426k/1.06G [00:01<48:58, 360kB/s]  \u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.1%| 737k/1.06G [00:01<33:10, 531kB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.1%| 1.11M/1.06G [00:01<25:18, 696kB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.1%| 1.56M/1.06G [00:01<22:35, 779kB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.2%| 2.23M/1.06G [00:02<17:03, 1.03MB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.3%| 2.90M/1.06G [00:02<14:38, 1.20MB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.3%| 3.57M/1.06G [00:02<13:58, 1.26MB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.4%| 4.24M/1.06G [00:03<14:12, 1.24MB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.5%| 4.92M/1.06G [00:03<13:04, 1.34MB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.5%| 5.59M/1.06G [00:04<12:44, 1.38MB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.6%| 6.26M/1.06G [00:04<12:28, 1.40MB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.7%| 6.93M/1.06G [00:04<11:51, 1.48MB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.7%| 7.60M/1.06G [00:05<11:42, 1.50MB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.8%| 8.27M/1.06G [00:05<11:35, 1.51MB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.8%| 8.95M/1.06G [00:05<11:08, 1.57MB/s]\u001B[A\u001B[A\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 0.9%| 9.62M/1.06G [00:06<11:05, 1.57MB/s]\u001B[A\u001B[A\n",
      "\n",
      "                  2.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: 1.0%| 10.3M/1.06G [00:06<11:02, 1.58MB/s]\u001B[A\u001B[A\r\n",
      "\n",
      "\u001B[A\u001B[A                                                                                                                        \n",
      "\u001B[A                                                                   [INFO] [error] https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: [00:06] [10.6MB] [1.61MB/s]\n",
      "0it [00:07, ?it/s]\n",
      "\n",
      "https://msmarco.z22.web.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: [00:06] [10.6MB] [1.61MB/s]\u001B[A\u001B[A\n",
      "msmarco-passage documents:   0%|          | 0/8841823 [00:07<?, ?it/s]\u001B[A\n",
      "\n",
      "msmarco-passage documents:   0%|          | 0/8841823 [00:07<?, ?it/s]                                          \u001B[A\u001B[A\n",
      "0it [00:07, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m ff_indexer \u001B[38;5;241m=\u001B[39m Indexer(ff_index, d_encoder, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mff_indexer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex_dicts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocs_iter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/fast_forward/indexer.py:36\u001B[0m, in \u001B[0;36mIndexer.index_dicts\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Index data from dictionaries.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;03mThe dictionaries should have the key \"text\" and at least one of \"doc_id\" and \"psg_id\".\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \n\u001B[1;32m     32\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;124;03m    data (Iterable[Dict[str, str]]): An iterable of the dictionaries.\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     35\u001B[0m texts, doc_ids, psg_ids \u001B[38;5;241m=\u001B[39m [], [], []\n\u001B[0;32m---> 36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m tqdm(data):\n\u001B[1;32m     37\u001B[0m     texts\u001B[38;5;241m.\u001B[39mappend(d[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdoc_id\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m d:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[7], line 3\u001B[0m, in \u001B[0;36mdocs_iter\u001B[0;34m(dataset, limit)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdocs_iter\u001B[39m(dataset, limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m# Iterate over the documents and yield up to 'limit' documents\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m count, d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataset\u001B[38;5;241m.\u001B[39mget_corpus_iter()):\n\u001B[1;32m      4\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m count \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m limit:\n\u001B[1;32m      5\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/datasets.py:418\u001B[0m, in \u001B[0;36mIRDSDataset.get_corpus_iter.<locals>.gen\u001B[0;34m()\u001B[0m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgen\u001B[39m():\n\u001B[0;32m--> 418\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[1;32m    419\u001B[0m         doc \u001B[38;5;241m=\u001B[39m doc\u001B[38;5;241m.\u001B[39m_asdict()\n\u001B[1;32m    420\u001B[0m         \u001B[38;5;66;03m# pyterrier uses \"docno\"\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/util/__init__.py:147\u001B[0m, in \u001B[0;36mDocstoreSplitter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mit\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/formats/tsv.py:92\u001B[0m, in \u001B[0;36mTsvIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 92\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mline_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m     cols \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39mrstrip(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     94\u001B[0m     num_cols \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcls\u001B[38;5;241m.\u001B[39m_fields)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/formats/tsv.py:28\u001B[0m, in \u001B[0;36mFileLineIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mTextIOWrapper(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctxt\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdlc[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream_idx]\u001B[38;5;241m.\u001B[39mstream()))\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 28\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mTextIOWrapper(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctxt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menter_context\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdlc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstart:\n\u001B[1;32m     30\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream\u001B[38;5;241m.\u001B[39mreadline()\n",
      "File \u001B[0;32m/usr/lib/python3.10/contextlib.py:492\u001B[0m, in \u001B[0;36m_BaseExitStack.enter_context\u001B[0;34m(self, cm)\u001B[0m\n\u001B[1;32m    490\u001B[0m _cm_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(cm)\n\u001B[1;32m    491\u001B[0m _exit \u001B[38;5;241m=\u001B[39m _cm_type\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__exit__\u001B[39m\n\u001B[0;32m--> 492\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43m_cm_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__enter__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_push_cm_exit(cm, _exit)\n\u001B[1;32m    494\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/usr/lib/python3.10/contextlib.py:135\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__enter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerator didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt yield\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/util/fileio.py:78\u001B[0m, in \u001B[0;36mCache.stream\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;129m@contextlib\u001B[39m\u001B[38;5;241m.\u001B[39mcontextmanager\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstream\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 78\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverify\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_path\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     80\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m f\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/util/fileio.py:69\u001B[0m, in \u001B[0;36mCache.verify\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_streamer\u001B[38;5;241m.\u001B[39mstream() \u001B[38;5;28;01mas\u001B[39;00m stream:\n\u001B[0;32m---> 69\u001B[0m         \u001B[43mshutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopyfileobj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m     f\u001B[38;5;241m.\u001B[39mclose() \u001B[38;5;66;03m# close file before move... Needed because of Windows\u001B[39;00m\n\u001B[1;32m     71\u001B[0m     shutil\u001B[38;5;241m.\u001B[39mmove(f\u001B[38;5;241m.\u001B[39mname, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_path)\n",
      "File \u001B[0;32m/usr/lib/python3.10/shutil.py:195\u001B[0m, in \u001B[0;36mcopyfileobj\u001B[0;34m(fsrc, fdst, length)\u001B[0m\n\u001B[1;32m    193\u001B[0m fdst_write \u001B[38;5;241m=\u001B[39m fdst\u001B[38;5;241m.\u001B[39mwrite\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 195\u001B[0m     buf \u001B[38;5;241m=\u001B[39m \u001B[43mfsrc_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlength\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m buf:\n\u001B[1;32m    197\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/util/fileio.py:35\u001B[0m, in \u001B[0;36mIterStream.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m pos \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(b):\n\u001B[1;32m     34\u001B[0m     l \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(b) \u001B[38;5;241m-\u001B[39m pos  \u001B[38;5;66;03m# We're supposed to return at most this much\u001B[39;00m\n\u001B[0;32m---> 35\u001B[0m     chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleftover \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m     output, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleftover \u001B[38;5;241m=\u001B[39m chunk[:l], chunk[l:]\n\u001B[1;32m     37\u001B[0m     b[pos:pos\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mlen\u001B[39m(output)] \u001B[38;5;241m=\u001B[39m output\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/datasets/msmarco_passage.py:81\u001B[0m, in \u001B[0;36mFixEncoding.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;66;03m# Find sequences of up to 4 characters that contain a suspicious character.\u001B[39;00m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;66;03m# We'll attempt to interpret these as latin1 characters and then decode them back to UTF8.\u001B[39;00m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# With this technique, we get 100% matches with MS MARCO QnA passages (which do not have this encoding issue)\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# This approach is more than twice as fast as using ftfy\u001B[39;00m\n\u001B[1;32m     76\u001B[0m regexes \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     77\u001B[0m     re\u001B[38;5;241m.\u001B[39mcompile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(...\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m|..\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.|.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m..|\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...)\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m     78\u001B[0m     re\u001B[38;5;241m.\u001B[39mcompile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(..\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m|.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.|\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m..)\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m     79\u001B[0m     re\u001B[38;5;241m.\u001B[39mcompile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m|\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.)\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m     80\u001B[0m ]\n\u001B[0;32m---> 81\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_streamer\u001B[38;5;241m.\u001B[39mstream() \u001B[38;5;28;01mas\u001B[39;00m stream, \\\n\u001B[1;32m     82\u001B[0m      _logger\u001B[38;5;241m.\u001B[39mpbar_raw(desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfixing encoding\u001B[39m\u001B[38;5;124m'\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m'\u001B[39m, unit_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[1;32m     83\u001B[0m      \u001B[38;5;66;03m# NOTE: codecs.getreader is subtly broken here; it sometimes splits lines between special characters (and it's unclear why)\u001B[39;00m\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m stream:\n\u001B[1;32m     85\u001B[0m         pbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mlen\u001B[39m(line))\n",
      "File \u001B[0;32m/usr/lib/python3.10/contextlib.py:135\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__enter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerator didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt yield\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/util/fileio.py:96\u001B[0m, in \u001B[0;36mTarExtract.stream\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;129m@contextlib\u001B[39m\u001B[38;5;241m.\u001B[39mcontextmanager\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstream\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 96\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m contextlib\u001B[38;5;241m.\u001B[39mExitStack() \u001B[38;5;28;01mas\u001B[39;00m ctxt, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_streamer\u001B[38;5;241m.\u001B[39mstream() \u001B[38;5;28;01mas\u001B[39;00m stream:\n\u001B[1;32m     97\u001B[0m         \u001B[38;5;66;03m# IMPORTANT: open this file in streaming mode (| in mode). This means that the\u001B[39;00m\n\u001B[1;32m     98\u001B[0m         \u001B[38;5;66;03m# content need not be written to disk or be fully read.\u001B[39;00m\n\u001B[1;32m     99\u001B[0m         tarf \u001B[38;5;241m=\u001B[39m ctxt\u001B[38;5;241m.\u001B[39menter_context(tarfile\u001B[38;5;241m.\u001B[39mopen(fileobj\u001B[38;5;241m=\u001B[39mstream, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr|\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compression\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mor\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m    100\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m block \u001B[38;5;129;01min\u001B[39;00m tarf:\n",
      "File \u001B[0;32m/usr/lib/python3.10/contextlib.py:135\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__enter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerator didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt yield\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/util/download.py:275\u001B[0m, in \u001B[0;36mDownload.stream\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    273\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m stream\n\u001B[1;32m    274\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 275\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m    276\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m f\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/util/download.py:252\u001B[0m, in \u001B[0;36mDownload.path\u001B[0;34m(self, force)\u001B[0m\n\u001B[1;32m    250\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m mirror\u001B[38;5;241m.\u001B[39mstream() \u001B[38;5;28;01mas\u001B[39;00m stream:\n\u001B[1;32m    251\u001B[0m             stream \u001B[38;5;241m=\u001B[39m util\u001B[38;5;241m.\u001B[39mHashStream(stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexpected_md5, algo\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmd5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 252\u001B[0m             \u001B[43mshutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopyfileobj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    253\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/usr/lib/python3.10/shutil.py:195\u001B[0m, in \u001B[0;36mcopyfileobj\u001B[0;34m(fsrc, fdst, length)\u001B[0m\n\u001B[1;32m    193\u001B[0m fdst_write \u001B[38;5;241m=\u001B[39m fdst\u001B[38;5;241m.\u001B[39mwrite\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 195\u001B[0m     buf \u001B[38;5;241m=\u001B[39m \u001B[43mfsrc_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlength\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m buf:\n\u001B[1;32m    197\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/util/hash.py:48\u001B[0m, in \u001B[0;36mHashStream.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreadinto\u001B[39m(\u001B[38;5;28mself\u001B[39m, b):\n\u001B[0;32m---> 48\u001B[0m     count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_verifier\u001B[38;5;241m.\u001B[39mupdate(b[:count])\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m count \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/util/fileio.py:35\u001B[0m, in \u001B[0;36mIterStream.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m pos \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(b):\n\u001B[1;32m     34\u001B[0m     l \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(b) \u001B[38;5;241m-\u001B[39m pos  \u001B[38;5;66;03m# We're supposed to return at most this much\u001B[39;00m\n\u001B[0;32m---> 35\u001B[0m     chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleftover \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m     output, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleftover \u001B[38;5;241m=\u001B[39m chunk[:l], chunk[l:]\n\u001B[1;32m     37\u001B[0m     b[pos:pos\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mlen\u001B[39m(output)] \u001B[38;5;241m=\u001B[39m output\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/util/download.py:97\u001B[0m, in \u001B[0;36mRequestsDownload.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     95\u001B[0m         pbar_f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;66;03m# defaults to stderr\u001B[39;00m\n\u001B[1;32m     96\u001B[0m     pbar \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(_logger\u001B[38;5;241m.\u001B[39mpbar_raw(desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murl, total\u001B[38;5;241m=\u001B[39mdlen, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m'\u001B[39m, unit_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, bar_format\u001B[38;5;241m=\u001B[39mfmt, file\u001B[38;5;241m=\u001B[39mpbar_f))\n\u001B[0;32m---> 97\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter_response_data(response, http_args, skip):\n\u001B[1;32m     98\u001B[0m     pbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mlen\u001B[39m(data))\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccept-ranges\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbytes\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    100\u001B[0m         \u001B[38;5;66;03m# since we got more data and the server accepts range requests, reset the \"tries\" counter\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/ir_datasets/util/download.py:145\u001B[0m, in \u001B[0;36mRequestsDownload._iter_response_data\u001B[0;34m(self, response, http_args, skip)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    144\u001B[0m     data_iter \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39miter_content(chunk_size\u001B[38;5;241m=\u001B[39mio\u001B[38;5;241m.\u001B[39mDEFAULT_BUFFER_SIZE)\n\u001B[0;32m--> 145\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m data_iter:\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m skip \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    147\u001B[0m         data, skipped \u001B[38;5;241m=\u001B[39m data[skip:], \u001B[38;5;28mlen\u001B[39m(data[:skip])\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py:816\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 816\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    817\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:576\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m    574\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp):\n\u001B[0;32m--> 576\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    578\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[1;32m    579\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:519\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[1;32m    517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    518\u001B[0m     cache_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m--> 519\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    520\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    521\u001B[0m         amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data\n\u001B[1;32m    522\u001B[0m     ):  \u001B[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    528\u001B[0m         \u001B[38;5;66;03m# not properly close the connection in all cases. There is\u001B[39;00m\n\u001B[1;32m    529\u001B[0m         \u001B[38;5;66;03m# no harm in redundantly calling close.\u001B[39;00m\n\u001B[1;32m    530\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m/usr/lib/python3.10/http/client.py:466\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength:\n\u001B[1;32m    464\u001B[0m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[1;32m    465\u001B[0m     amt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength\n\u001B[0;32m--> 466\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[1;32m    468\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    469\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    470\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m/usr/lib/python3.10/socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.10/ssl.py:1303\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1299\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1300\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1301\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1302\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1303\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1304\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1305\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m/usr/lib/python3.10/ssl.py:1159\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1159\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1160\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1161\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ff_indexer = Indexer(ff_index, d_encoder, batch_size=8)\n",
    "ff_indexer.index_dicts(docs_iter(dataset))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
