{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## In this notebook we will showcase the experiments realised using the FFI framework with the tct_colbert finetuned on the msmarco dataset encoder for the following datasets:\n",
    "\n",
    "* irds:beir/nfcorpus\n",
    "* irds:beir/fiqa\n",
    "* irds:beir/scidocs\n",
    "* irds:beir/cqadupstack/english\n",
    "* irds:beir/arguana\n",
    "* irds:beir/scifact"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "General Setup for all the datasets( first 4 cells)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluation metrics used for all the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "\n",
    "eval_metrics = [RR @ 10, nDCG @ 10, MAP @ 100]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the query encoder that will run on CPU. Encoder used for embedding all the datasets/queries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at castorini/tct_colbert-msmarco were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from fast_forward.encoder import TCTColBERTQueryEncoder\n",
    "\n",
    "model_name = \"tct_colbert_msmarco\"\n",
    "q_encoder = TCTColBERTQueryEncoder(\"castorini/tct_colbert-msmarco\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defined the path to root"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "path_to_root = \"../../\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following cells, for each dataset we will run FFI using BM25 for the first stage retrieval and bge-base-en-v1.5 for the semantic re-ranking:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BM25 >> tct_colbert irds:beir/nfcorpus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3633/3633 [00:00<00:00, 1698195.30it/s]\n",
      "GridScan: 100%|██████████| 4/4 [00:50<00:00, 12.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best map is 0.114519\n",
      "Best setting is ['<fast_forward.util.pyterrier.FFInterpolate object at 0x7fa1130eabf0> alpha=0.02']\n",
      "Experiment took 14.851 seconds to execute.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                    name     RR@10   nDCG@10    AP@100\n0  nfcorpus: BM25 >> tct_colbert_msmarco  0.522044  0.318184  0.144755",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nfcorpus: BM25 &gt;&gt; tct_colbert_msmarco</td>\n      <td>0.522044</td>\n      <td>0.318184</td>\n      <td>0.144755</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment_utils.experiments_helper import default_test_pipeline_name\n",
    "\n",
    "dataset_name = \"irds:beir/nfcorpus\"\n",
    "dev_set_name = \"irds:beir/nfcorpus/dev\"\n",
    "dataset_test_name = \"irds:beir/nfcorpus/test\"\n",
    "pipeline_name = \"BM25 >> \" + model_name\n",
    "\n",
    "default_test_pipeline_name(dataset_name, dataset_test_name, q_encoder, eval_metrics, model_name, pipeline_name,\n",
    "                           path_to_root, dev_set_name=dev_set_name, timed=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BM25 >> tct_colbert irds:beir/fiqa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from experiment_utils.experiments_helper import default_test_pipeline_name\n",
    "\n",
    "dataset_name = \"irds:beir/fiqa\"\n",
    "dev_set_name = \"irds:beir/fiqa/dev\"\n",
    "dataset_test_name = \"irds:beir/fiqa/test\"\n",
    "pipeline_name = \"BM25 >> \" + model_name\n",
    "\n",
    "default_test_pipeline_name(dataset_name, dataset_test_name, q_encoder, eval_metrics, model_name, pipeline_name,\n",
    "                           path_to_root, dev_set_name=dev_set_name, timed=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BM25 >> tct_colbert irds:beir/scidocs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from experiment_utils.experiments_helper import default_test_pipeline\n",
    "\n",
    "dataset_name = \"irds:beir/scidocs\"\n",
    "dataset = pt.get_dataset(dataset_name)\n",
    "test_topics = dataset.get_topics('text')\n",
    "test_qrels = dataset.get_qrels()\n",
    "pipeline_name = \"BM25 >> \" + model_name\n",
    "\n",
    "default_test_pipeline(dataset_name, test_topics, test_qrels, q_encoder, eval_metrics, model_name, pipeline_name,\n",
    "                      path_to_root, timed=True, alpha=0.05)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BM25 >> tct_colbert irds:beir/cscqadupstack/english"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from experiment_utils.experiments_helper import default_test_pipeline\n",
    "\n",
    "dataset_name = \"irds:beir/cqadupstack/english\"\n",
    "dataset = pt.get_dataset(\"irds:beir/cqadupstack/english\")\n",
    "test_topics = dataset.get_topics('text')\n",
    "test_qrels = dataset.get_qrels()\n",
    "pipeline_name = \"BM25 >> \" + model_name\n",
    "\n",
    "default_test_pipeline(dataset_name, test_topics, test_qrels, q_encoder, eval_metrics, model_name, pipeline_name,\n",
    "                      path_to_root, timed=True, alpha=0.05)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BM25 >> tct_colbert irds:beir/arguana\n",
    "\n",
    "#### Local runtime : x minutes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8674/8674 [00:00<00:00, 1027258.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment took 214.066 seconds to execute.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                   name     RR@10   nDCG@10    AP@100\n0  arguana: BM25 >> tct_colbert_msmarco  0.187759  0.288036  0.202261",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>arguana: BM25 &gt;&gt; tct_colbert_msmarco</td>\n      <td>0.187759</td>\n      <td>0.288036</td>\n      <td>0.202261</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment_utils.experiments_helper import default_test_pipeline_name\n",
    "\n",
    "dataset_name = \"irds:beir/arguana\"\n",
    "pipeline_name = \"BM25 >> \" + model_name\n",
    "\n",
    "default_test_pipeline_name(dataset_name, dataset_name, q_encoder, eval_metrics, model_name, pipeline_name, path_to_root,\n",
    "                           timed=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BM25 >> tct_colbert irds:beir/scifact"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 1437484.47it/s]\n",
      "GridScan: 100%|██████████| 4/4 [02:34<00:00, 38.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best map is 0.621427\n",
      "Best setting is ['<fast_forward.util.pyterrier.FFInterpolate object at 0x7fa074c89150> alpha=0.02']\n",
      "Experiment took 18.839 seconds to execute.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                   name     RR@10   nDCG@10    AP@100\n0  scifact: BM25 >> tct_colbert_msmarco  0.592106  0.623456  0.583593",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@10</th>\n      <th>AP@100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>scifact: BM25 &gt;&gt; tct_colbert_msmarco</td>\n      <td>0.592106</td>\n      <td>0.623456</td>\n      <td>0.583593</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment_utils.experiments_helper import default_test_pipeline_name\n",
    "\n",
    "dataset_name = \"irds:beir/scifact\"\n",
    "dataset_test_name = \"irds:beir/scifact/test\"\n",
    "dev_set_name = \"irds:beir/scifact/train\"\n",
    "pipeline_name = \"BM25 >> \" + model_name\n",
    "\n",
    "default_test_pipeline_name(dataset_name, dataset_test_name, q_encoder, eval_metrics, model_name, pipeline_name,\n",
    "                           path_to_root, dev_set_name=dev_set_name, timed=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BM25 >> tct_colbert irds:msmarco-passage/trec-dl-2019"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [starting] opening zip file\n",
      "[INFO] If you have a local copy of https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/msmarco.zip, you can symlink it here to avoid downloading it again: /home/anistor/.ir_datasets/downloads/444067daf65d982533ea17ebd59501e4\n",
      "[INFO] [starting] https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/msmarco.zip\n",
      "[INFO] [finished] https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/msmarco.zip: [00:38] [1.08GB] [27.8MB/s]\n",
      "[INFO] [finished] opening zip file [39.18s]                                                                \n",
      "[INFO] [starting] opening zip file\n",
      "[INFO] [finished] opening zip file [0ms]\n",
      "100%|██████████| 8841823/8841823 [00:11<00:00, 793875.48it/s] \n",
      "GridScan:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from experiment_utils.experiments_helper import default_test_pipeline_name\n",
    "from config.sparse_pyterrier_index_global_paths import MSMARCO_PASSAGE_TERRIER_STEMMED_PATH\n",
    "\n",
    "dataset_test_name = \"irds:msmarco-passage/trec-dl-2019\"\n",
    "dev_set_name = \"irds:beir/msmarco/dev\"\n",
    "pipeline_name = \"BM25 >> \" + model_name\n",
    "default_test_pipeline_name(dataset_test_name, dataset_test_name, q_encoder, eval_metrics, model_name, pipeline_name,\n",
    "                           path_to_root, dev_set_name=dev_set_name, timed=True, in_memory_sparse=False,\n",
    "                           in_memory_dense=False, index_path=MSMARCO_PASSAGE_TERRIER_STEMMED_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
