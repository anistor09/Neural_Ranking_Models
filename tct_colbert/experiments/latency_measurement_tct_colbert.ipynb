{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "from experiment_utils.experiments_helper import get_timeit_dependencies_name, getOptimalAlpha, latency_per_query\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anistor/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from fast_forward.encoder import TCTColBERTQueryEncoder\n",
    "\n",
    "package = \"castorini/\"\n",
    "model_name = \"tct_colbert-msmarco\"\n",
    "q_encoder = TCTColBERTQueryEncoder(package + model_name)\n",
    "model_directory = 'tct_colbert'\n",
    "path_to_root = \"../../\"\n",
    "pipeline_name = \"BM25 >> \" + \"tct_colbert_msmarco\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "prefix = \"irds:\"\n",
    "test_suffix = \"/trec-dl-2019\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_timeit_dep(dataset_name):\n",
    "    return get_timeit_dependencies_name(prefix + dataset_name, prefix + dataset_name + test_suffix,\n",
    "                                        q_encoder,\n",
    "                                        model_name,\n",
    "                                        path_to_root, model_directory,\n",
    "                                        alpha=getOptimalAlpha(prefix + dataset_name, pipeline_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No third element available\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m dataset_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfiqa\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m results_lexical_retriever, semantic_reranker \u001B[38;5;241m=\u001B[39m \u001B[43mget_timeit_dep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[5], line 6\u001B[0m, in \u001B[0;36mget_timeit_dep\u001B[0;34m(dataset_name)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_timeit_dep\u001B[39m(dataset_name):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_timeit_dependencies_name(prefix \u001B[38;5;241m+\u001B[39m dataset_name, prefix \u001B[38;5;241m+\u001B[39m dataset_name \u001B[38;5;241m+\u001B[39m test_suffix,\n\u001B[1;32m      3\u001B[0m                                         q_encoder,\n\u001B[1;32m      4\u001B[0m                                         model_name,\n\u001B[1;32m      5\u001B[0m                                         path_to_root, model_directory,\n\u001B[0;32m----> 6\u001B[0m                                         alpha\u001B[38;5;241m=\u001B[39m\u001B[43mgetOptimalAlpha\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprefix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpipeline_name\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/experiment_utils/experiments_helper.py:293\u001B[0m, in \u001B[0;36mgetOptimalAlpha\u001B[0;34m(dataset_name, pipeline_name)\u001B[0m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgetOptimalAlpha\u001B[39m(dataset_name, pipeline_name):\n\u001B[0;32m--> 293\u001B[0m     experiment_name \u001B[38;5;241m=\u001B[39m \u001B[43mget_dataset_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m: \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m \u001B[38;5;241m+\u001B[39m pipeline_name\n\u001B[1;32m    294\u001B[0m     \u001B[38;5;28mprint\u001B[39m(experiment_name)\n\u001B[1;32m    295\u001B[0m     path_to_root \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(os\u001B[38;5;241m.\u001B[39mgetcwd())\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "dataset_name = \"fiqa\"\n",
    "results_lexical_retriever, semantic_reranker = get_timeit_dep(dataset_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "%%capture captured_timeit_output\n",
    "%timeit semantic_reranker(results_lexical_retriever)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'Latency per query: 22.8019 ms. (Info: 7 runs, 1 loop each)'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latency_per_query(captured_timeit_output.stdout, prefix + dataset_name + test_suffix, pipeline_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3633/3633 [00:00<00:00, 931298.52it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"nfcorpus\"\n",
    "results_lexical_retriever, semantic_reranker = get_timeit_dep(dataset_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "%%capture captured_timeit_output\n",
    "%timeit semantic_reranker(results_lexical_retriever)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'Latency per query: 0.8594 ms. (Info: 7 runs, 1 loop each)'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latency_per_query(captured_timeit_output.stdout, prefix + dataset_name + test_suffix, pipeline_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 1548146.82it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"scifact\"\n",
    "results_lexical_retriever, semantic_reranker = get_timeit_dep(dataset_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "%%capture captured_timeit_output\n",
    "%timeit semantic_reranker(results_lexical_retriever)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'Latency per query: 37.1681 ms. (Info: 7 runs, 1 loop each)'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latency_per_query(captured_timeit_output.stdout, prefix + dataset_name + test_suffix, pipeline_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passage: BM25 >> tct_colbert_msmarco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8841823/8841823 [00:14<00:00, 589637.77it/s] \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 25.3 GiB for an array with shape (8841823, 768) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m dataset_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmsmarco-passage\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m results_lexical_retriever, semantic_reranker \u001B[38;5;241m=\u001B[39m \u001B[43mget_timeit_dep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[9], line 2\u001B[0m, in \u001B[0;36mget_timeit_dep\u001B[0;34m(dataset_name)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_timeit_dep\u001B[39m(dataset_name):\n\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_timeit_dependencies_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprefix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtest_suffix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mq_encoder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mpath_to_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgetOptimalAlpha\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprefix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpipeline_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/experiment_utils/experiments_helper.py:209\u001B[0m, in \u001B[0;36mget_timeit_dependencies_name\u001B[0;34m(dataset_name, test_set_name, q_encoder, model_name, path_to_root, model_directory, dev_set_name, alpha, in_memory_sparse, in_memory_dense, index_path)\u001B[0m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_timeit_dependencies_name\u001B[39m(dataset_name, test_set_name, q_encoder, model_name,\n\u001B[1;32m    205\u001B[0m                                  path_to_root, model_directory, dev_set_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.005\u001B[39m, in_memory_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    206\u001B[0m                                  in_memory_dense\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, index_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m     test_topics, test_qrels, dev_topics, dev_qrels \u001B[38;5;241m=\u001B[39m get_test_dev_sets(test_set_name, dev_set_name)\n\u001B[0;32m--> 209\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_timeit_dependencies\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_topics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_encoder\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath_to_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    211\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mdev_topics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdev_qrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43min_memory_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43min_memory_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43min_memory_dense\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43min_memory_dense\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mindex_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/experiment_utils/experiments_helper.py:250\u001B[0m, in \u001B[0;36mget_timeit_dependencies\u001B[0;34m(dataset_name, test_topics, q_encoder, model_name, path_to_root, model_directory, dev_topics, dev_qrels, alpha, in_memory_sparse, in_memory_dense, index_path)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_timeit_dependencies\u001B[39m(dataset_name, test_topics, q_encoder, model_name,\n\u001B[1;32m    247\u001B[0m                             path_to_root, model_directory, dev_topics\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dev_qrels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.005\u001B[39m,\n\u001B[1;32m    248\u001B[0m                             in_memory_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    249\u001B[0m                             in_memory_dense\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, index_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 250\u001B[0m     sparse_retriever, semantic_reranker, optimal_alpha \u001B[38;5;241m=\u001B[39m \u001B[43mget_pipeline_transformers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_encoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[43m                                                                                   \u001B[49m\u001B[43mpath_to_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m                                                                                   \u001B[49m\u001B[43mdev_topics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdev_topics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m                                                                                   \u001B[49m\u001B[43mdev_qrels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdev_qrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m                                                                                   \u001B[49m\u001B[43min_memory_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43min_memory_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m                                                                                   \u001B[49m\u001B[43min_memory_dense\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43min_memory_dense\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m                                                                                   \u001B[49m\u001B[43mindex_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    257\u001B[0m     first_stage_results \u001B[38;5;241m=\u001B[39m sparse_retriever(test_topics)\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dev_topics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/experiment_utils/experiments_helper.py:225\u001B[0m, in \u001B[0;36mget_pipeline_transformers\u001B[0;34m(dataset_name, q_encoder, model_name, path_to_root, model_directory, dev_topics, dev_qrels, alpha, in_memory_sparse, in_memory_dense, index_path)\u001B[0m\n\u001B[1;32m    221\u001B[0m retriever \u001B[38;5;241m=\u001B[39m load_sparse_index_from_disk(dataset_name, path_to_root, in_memory\u001B[38;5;241m=\u001B[39min_memory_sparse,\n\u001B[1;32m    222\u001B[0m                                         index_path\u001B[38;5;241m=\u001B[39mindex_path)\n\u001B[1;32m    224\u001B[0m \u001B[38;5;66;03m# Dense index\u001B[39;00m\n\u001B[0;32m--> 225\u001B[0m dense_index \u001B[38;5;241m=\u001B[39m \u001B[43mload_dense_index_from_disk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_encoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath_to_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43min_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43min_memory_dense\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    228\u001B[0m ff_score \u001B[38;5;241m=\u001B[39m FFScore(dense_index)\n\u001B[1;32m    229\u001B[0m \u001B[38;5;66;03m# ff_int = FFInterpolate(alpha=alpha)\u001B[39;00m\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/experiment_utils/experiments_helper.py:45\u001B[0m, in \u001B[0;36mload_dense_index_from_disk\u001B[0;34m(dataset_name, query_encoder, model_name, path_to_root, model_directory, mode, in_memory)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# Return index loaded into memory\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m in_memory:\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mff_index\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ff_index\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/fast_forward_indexes_library_enhancements/disk.py:128\u001B[0m, in \u001B[0;36mOnDiskIndex.to_memory\u001B[0;34m(self, buffer_size)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;66;03m# we can only add vectors of the same type (doc IDs, passage IDs, or both) in one batch\u001B[39;00m\n\u001B[1;32m    127\u001B[0m has_doc_id, has_psg_id, has_both_ids \u001B[38;5;241m=\u001B[39m [], [], []\n\u001B[0;32m--> 128\u001B[0m vecs \u001B[38;5;241m=\u001B[39m \u001B[43mfp\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvectors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi_low\u001B[49m\u001B[43m:\u001B[49m\u001B[43mi_up\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    129\u001B[0m doc_ids \u001B[38;5;241m=\u001B[39m fp[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdoc_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39masstr()[i_low:i_up]\n\u001B[1;32m    130\u001B[0m psg_ids \u001B[38;5;241m=\u001B[39m fp[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpsg_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39masstr()[i_low:i_up]\n",
      "File \u001B[0;32mh5py/_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/dataset.py:758\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[0;34m(self, args, new_dtype)\u001B[0m\n\u001B[1;32m    756\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fast_read_ok \u001B[38;5;129;01mand\u001B[39;00m (new_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    757\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 758\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fast_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    759\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    760\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Fall back to Python read pathway below\u001B[39;00m\n",
      "File \u001B[0;32mh5py/_selector.pyx:368\u001B[0m, in \u001B[0;36mh5py._selector.Reader.read\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/_selector.pyx:342\u001B[0m, in \u001B[0;36mh5py._selector.Reader.make_array\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mMemoryError\u001B[0m: Unable to allocate 25.3 GiB for an array with shape (8841823, 768) and data type float32"
     ]
    }
   ],
   "source": [
    "dataset_name = \"msmarco-passage\"\n",
    "results_lexical_retriever, semantic_reranker = get_timeit_dep(dataset_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture captured_timeit_output\n",
    "%timeit semantic_reranker(results_lexical_retriever)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
