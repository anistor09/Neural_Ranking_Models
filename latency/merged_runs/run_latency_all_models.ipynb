{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "import pyterrier as pt\n",
    "from experiment_utils.experiments_helper import get_timeit_dependencies_name, getOptimalAlpha, latency_per_query\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from encoders.bge_base_en import BgeQueryEncoder\n",
    "\n",
    "package = \"BAAI/\"\n",
    "model_name = \"bge-base-en-v1.5\"\n",
    "q_encoder = BgeQueryEncoder(package + model_name)\n",
    "model_directory = 'bge'\n",
    "path_to_root = \"../../\"\n",
    "pipeline_name = \"BM25 >> bge-base-en-v1.5\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "prefix = \"irds:beir/\"\n",
    "test_suffix = \"/test\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_timeit_dep(dataset_name):\n",
    "    return get_timeit_dependencies_name(prefix + dataset_name, prefix + dataset_name + test_suffix,\n",
    "                                        q_encoder,\n",
    "                                        model_name,\n",
    "                                        path_to_root, model_directory,\n",
    "                                        alpha=getOptimalAlpha(prefix + dataset_name, pipeline_name, model_directory))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "\n",
    "def measure_latency(dataset_name):\n",
    "    results_lexical_retriever, semantic_reranker = get_timeit_dep(dataset_name)\n",
    "    f = io.StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        %timeit semantic_reranker(results_lexical_retriever)\n",
    "\n",
    "    timeit_output = f.getvalue()\n",
    "    result = latency_per_query(timeit_output, prefix + dataset_name, test_suffix, pipeline_name, model_directory)\n",
    "    print(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataset_list = [\"fiqa\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "\n",
    "def run_latency_datasets():\n",
    "    for dataset_name in dataset_list:\n",
    "        try:\n",
    "            measure_latency(dataset_name)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57638/57638 [00:00<00:00, 1394512.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.7 s +- 1.02 s per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Latency per query: 41.2037 ms. Experiment details: 26.7 s +- 1.02 s per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_latency_datasets()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3633/3633 [00:00<00:00, 1648945.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency per query: 8.0495 ms. Experiment details: 2.6 s +- 101 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57638/57638 [00:00<00:00, 425652.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency per query: 18.5185 ms. Experiment details: 12 s +- 479 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 1162890.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency per query: 20.9667 ms. Experiment details: 6.29 s +- 187 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bge-small-en-v1.5\"\n",
    "pipeline_name = \"BM25 >> \" + model_name\n",
    "q_encoder = BgeQueryEncoder(package + model_name)\n",
    "\n",
    "run_latency_datasets()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57638/57638 [00:00<00:00, 1420837.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.1 s +- 2.11 s per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Latency per query: 43.3642 ms. Experiment details: 28.1 s +- 2.11 s per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from encoders.gte_base_en_encoder import GTEBaseEncoder\n",
    "\n",
    "package = \"Alibaba-NLP/\"\n",
    "model_name = \"gte-base-en-v1.5\"\n",
    "q_encoder = GTEBaseEncoder(package + model_name)\n",
    "model_directory = 'gte_base_en_v1_5'\n",
    "pipeline_name = \"BM25 >> \" + model_name\n",
    "\n",
    "run_latency_datasets()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57638/57638 [00:00<00:00, 1539866.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.9 s +- 2.79 s per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Latency per query: 44.5988 ms. Experiment details: 28.9 s +- 2.79 s per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from encoders.snowflake_arctic_embed_m import SnowFlakeQueryEncoder\n",
    "\n",
    "package = \"Snowflake/\"\n",
    "model_name = \"snowflake-arctic-embed-m\"\n",
    "q_encoder = SnowFlakeQueryEncoder(package + model_name)\n",
    "model_directory = 'snowflake'\n",
    "pipeline_name = \"BM25 >> \" + model_name\n",
    "\n",
    "run_latency_datasets()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3633/3633 [00:00<00:00, 1646095.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency per query: 5.5728 ms. Experiment details: 1.8 s +- 154 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57638/57638 [00:00<00:00, 1529084.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency per query: 13.5802 ms. Experiment details: 8.8 s +- 249 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 1491020.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency per query: 14.7667 ms. Experiment details: 4.43 s +- 177 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"snowflake-arctic-embed-xs\"\n",
    "q_encoder = SnowFlakeQueryEncoder(package + model_name)\n",
    "\n",
    "for dataset_name in dataset_list:\n",
    "    measure_latency(dataset_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dataset_list = [\"fiqa\", \"nfcorpus\", \"scifact\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anistor/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 57638/57638 [00:00<00:00, 1257248.55it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m model_directory \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtct_colbert\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      7\u001B[0m pipeline_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBM25 >> \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtct_colbert_msmarco\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 9\u001B[0m \u001B[43mrun_latency_datasets\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[7], line 7\u001B[0m, in \u001B[0;36mrun_latency_datasets\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset_name \u001B[38;5;129;01min\u001B[39;00m dataset_list:\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m----> 7\u001B[0m         \u001B[43mmeasure_latency\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m      9\u001B[0m         traceback\u001B[38;5;241m.\u001B[39mprint_exc()\n",
      "Cell \u001B[0;32mIn[5], line 5\u001B[0m, in \u001B[0;36mmeasure_latency\u001B[0;34m(dataset_name)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmeasure_latency\u001B[39m(dataset_name):\n\u001B[0;32m----> 5\u001B[0m     results_lexical_retriever, semantic_reranker \u001B[38;5;241m=\u001B[39m \u001B[43mget_timeit_dep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m     f \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mStringIO()\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m redirect_stdout(f):\n",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m, in \u001B[0;36mget_timeit_dep\u001B[0;34m(dataset_name)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_timeit_dep\u001B[39m(dataset_name):\n\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_timeit_dependencies_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprefix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtest_suffix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mq_encoder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mpath_to_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgetOptimalAlpha\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprefix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpipeline_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_directory\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/experiment_utils/experiments_helper.py:237\u001B[0m, in \u001B[0;36mget_timeit_dependencies_name\u001B[0;34m(dataset_name, test_set_name, q_encoder, model_name, path_to_root, model_directory, dev_set_name, alpha, in_memory_sparse, in_memory_dense, index_path)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_timeit_dependencies_name\u001B[39m(dataset_name, test_set_name, q_encoder, model_name,\n\u001B[1;32m    233\u001B[0m                                  path_to_root, model_directory, dev_set_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.005\u001B[39m, in_memory_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    234\u001B[0m                                  in_memory_dense\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, index_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    235\u001B[0m     test_topics, test_qrels, dev_topics, dev_qrels \u001B[38;5;241m=\u001B[39m get_test_dev_sets(test_set_name, dev_set_name)\n\u001B[0;32m--> 237\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_timeit_dependencies\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_topics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_encoder\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath_to_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mdev_topics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdev_qrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43min_memory_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43min_memory_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43min_memory_dense\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43min_memory_dense\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mindex_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anistor-Neural-ranking-models/experiment_utils/experiments_helper.py:291\u001B[0m, in \u001B[0;36mget_timeit_dependencies\u001B[0;34m(dataset_name, test_topics, q_encoder, model_name, path_to_root, model_directory, dev_topics, dev_qrels, alpha, in_memory_sparse, in_memory_dense, index_path)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_timeit_dependencies\u001B[39m(dataset_name, test_topics, q_encoder, model_name,\n\u001B[1;32m    281\u001B[0m                             path_to_root, model_directory, dev_topics\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dev_qrels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.005\u001B[39m,\n\u001B[1;32m    282\u001B[0m                             in_memory_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    283\u001B[0m                             in_memory_dense\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, index_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    284\u001B[0m     sparse_retriever, semantic_reranker, optimal_alpha \u001B[38;5;241m=\u001B[39m get_pipeline_transformers(dataset_name, q_encoder, model_name,\n\u001B[1;32m    285\u001B[0m                                                                                    path_to_root, model_directory,\n\u001B[1;32m    286\u001B[0m                                                                                    dev_topics\u001B[38;5;241m=\u001B[39mdev_topics,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    289\u001B[0m                                                                                    in_memory_dense\u001B[38;5;241m=\u001B[39min_memory_dense,\n\u001B[1;32m    290\u001B[0m                                                                                    index_path\u001B[38;5;241m=\u001B[39mindex_path)\n\u001B[0;32m--> 291\u001B[0m     first_stage_results \u001B[38;5;241m=\u001B[39m \u001B[43msparse_retriever\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_topics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    293\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dev_topics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    294\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m first_stage_results, semantic_reranker, optimal_alpha\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/transformer.py:223\u001B[0m, in \u001B[0;36mTransformer.__call__\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;124;03m    Sets up a default method for every transformer, which is aliased to transform() (for DataFrames)\u001B[39;00m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;124;03m    or transform_iter() (for iterable dictionaries) depending on the type of input. \u001B[39;00m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28minput\u001B[39m, pd\u001B[38;5;241m.\u001B[39mDataFrame):\n\u001B[0;32m--> 223\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform_iter(\u001B[38;5;28minput\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/batchretrieve.py:441\u001B[0m, in \u001B[0;36mBatchRetrieve.transform\u001B[0;34m(self, queries)\u001B[0m\n\u001B[1;32m    439\u001B[0m         \u001B[38;5;28miter\u001B[39m \u001B[38;5;241m=\u001B[39m tqdm(\u001B[38;5;28miter\u001B[39m, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m), total\u001B[38;5;241m=\u001B[39mqueries\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m:\n\u001B[0;32m--> 441\u001B[0m         res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retrieve_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_results\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocno_provided\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdocno_provided\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocid_provided\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdocid_provided\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscores_provided\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscores_provided\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    442\u001B[0m         results\u001B[38;5;241m.\u001B[39mextend(res)\n\u001B[1;32m    444\u001B[0m res_dt \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(results, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mqid\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdocid\u001B[39m\u001B[38;5;124m'\u001B[39m ] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetadata \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrank\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyterrier/batchretrieve.py:368\u001B[0m, in \u001B[0;36mBatchRetrieve._retrieve_one\u001B[0;34m(self, row, input_results, docno_provided, docid_provided, scores_provided)\u001B[0m\n\u001B[1;32m    366\u001B[0m metadata_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    367\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m meta_column \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetadata:\n\u001B[0;32m--> 368\u001B[0m     metadata_list\u001B[38;5;241m.\u001B[39mappend(\u001B[43mitem\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetMetadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmeta_column\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    369\u001B[0m res \u001B[38;5;241m=\u001B[39m [qid, item\u001B[38;5;241m.\u001B[39mgetDocid()] \u001B[38;5;241m+\u001B[39m metadata_list \u001B[38;5;241m+\u001B[39m [rank, item\u001B[38;5;241m.\u001B[39mgetScore()]\n\u001B[1;32m    370\u001B[0m rank \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from fast_forward.encoder import TCTColBERTQueryEncoder\n",
    "\n",
    "package = \"castorini/\"\n",
    "model_name = \"tct_colbert-msmarco\"\n",
    "q_encoder = TCTColBERTQueryEncoder(package + model_name)\n",
    "model_directory = 'tct_colbert'\n",
    "pipeline_name = \"BM25 >> \" + 'tct_colbert_msmarco'\n",
    "\n",
    "run_latency_datasets()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
